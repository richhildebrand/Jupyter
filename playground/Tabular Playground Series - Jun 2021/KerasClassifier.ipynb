{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7599be49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.4 MB 56 kB/s  eta 0:00:015   |██▍                             | 33.9 MB 4.2 MB/s eta 0:01:41     |██▋                             | 37.5 MB 4.2 MB/s eta 0:01:40     |███▋                            | 52.0 MB 4.7 MB/s eta 0:01:26     |████▍                           | 61.8 MB 7.5 MB/s eta 0:00:53     |█████▎                          | 74.6 MB 7.3 MB/s eta 0:00:52     |████████                        | 112.4 MB 4.0 MB/s eta 0:01:25     |█████████▉                      | 138.9 MB 3.5 MB/s eta 0:01:30     |███████████▍                    | 161.1 MB 919 kB/s eta 0:05:20     |███████████████▉                | 225.5 MB 4.2 MB/s eta 0:00:55     |████████████████▋               | 235.2 MB 4.8 MB/s eta 0:00:46     |█████████████████               | 241.5 MB 3.6 MB/s eta 0:01:00     |███████████████████             | 271.2 MB 6.4 MB/s eta 0:00:29     |███████████████████▎            | 273.1 MB 6.4 MB/s eta 0:00:29     |████████████████████████▎       | 344.4 MB 4.9 MB/s eta 0:00:23     |█████████████████████████████▌  | 418.4 MB 4.5 MB/s eta 0:00:08     |█████████████████████████████▋  | 420.8 MB 3.2 MB/s eta 0:00:11     |███████████████████████████████ | 440.5 MB 5.3 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 638 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 3.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.17.2)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 2.0 MB/s eta 0:00:01    |███▊                            | 1.7 MB 6.8 MB/s eta 0:00:02     |█████████▌                      | 4.4 MB 6.8 MB/s eta 0:00:02     |███████████████████████████▋    | 12.8 MB 2.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.31.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow) (49.6.0.post20210108)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 3.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=6d6b61626ebdeb3b2028a4b465229d1826ebbb17343223d5d7af7cc716423422\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=37042 sha256=637457408ed44dcdd9c918d8c773dacb0f2a996f9891c6ffd1079654655edf2c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: pyasn1, six, rsa, pyasn1-modules, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.2.1\n",
      "    Uninstalling h5py-3.2.1:\n",
      "      Successfully uninstalled h5py-3.2.1\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.4.0 google-auth-1.31.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-2.0.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4b401424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b005e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d751b27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count:  160000\n",
      "test count:  40000\n"
     ]
    }
   ],
   "source": [
    "train_no_predict = train_df.drop(['id', 'target'], 1)\n",
    "train_predict = train_df['target']\n",
    "\n",
    "train_percent = 0.80\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_no_predict, train_predict, stratify=train_predict, train_size=train_percent)\n",
    "print('train count: ', len(y_train))\n",
    "print('test count: ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "306fa8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "dummy_y = dummy_y.astype(int)\n",
    "y_dim = np.shape(dummy_y)[1]\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "17949cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  1  0  0]\n",
      " [ 1  0  1 ...  0  1  0]\n",
      " [ 3  0  0 ...  1  0  0]\n",
      " ...\n",
      " [ 1  0 13 ...  0  2  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.astype(int)\n",
    "X_dim = np.shape(X_train)[1]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b3292e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_nodes = 10\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_dim=X_dim, activation='relu'))\n",
    "    model.add(Dense(y_dim, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2a268ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=60, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "30652487",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=25, shuffle=True, random_state=777)\n",
    "#skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-21 01:34:50.423832\n",
      "Epoch 1/60\n",
      "600/600 - 1s - loss: 2.4171 - accuracy: 0.2338\n",
      "Epoch 2/60\n",
      "600/600 - 1s - loss: 1.9435 - accuracy: 0.2808\n",
      "Epoch 3/60\n",
      "600/600 - 1s - loss: 1.8816 - accuracy: 0.3123\n",
      "Epoch 4/60\n",
      "600/600 - 1s - loss: 1.8411 - accuracy: 0.3329\n",
      "Epoch 5/60\n",
      "600/600 - 1s - loss: 1.8199 - accuracy: 0.3400\n",
      "Epoch 6/60\n",
      "600/600 - 1s - loss: 1.8068 - accuracy: 0.3425\n",
      "Epoch 7/60\n",
      "600/600 - 1s - loss: 1.7998 - accuracy: 0.3425\n",
      "Epoch 8/60\n",
      "600/600 - 1s - loss: 1.7966 - accuracy: 0.3434\n",
      "Epoch 9/60\n",
      "600/600 - 1s - loss: 1.7951 - accuracy: 0.3432\n",
      "Epoch 10/60\n",
      "600/600 - 1s - loss: 1.7938 - accuracy: 0.3446\n",
      "Epoch 11/60\n",
      "600/600 - 1s - loss: 1.7926 - accuracy: 0.3458\n",
      "Epoch 12/60\n",
      "600/600 - 1s - loss: 1.7911 - accuracy: 0.3468\n",
      "Epoch 13/60\n",
      "600/600 - 1s - loss: 1.7901 - accuracy: 0.3472\n",
      "Epoch 14/60\n",
      "600/600 - 1s - loss: 1.7891 - accuracy: 0.3482\n",
      "Epoch 15/60\n",
      "600/600 - 1s - loss: 1.7883 - accuracy: 0.3474\n",
      "Epoch 16/60\n",
      "600/600 - 1s - loss: 1.7875 - accuracy: 0.3488\n",
      "Epoch 17/60\n",
      "600/600 - 1s - loss: 1.7870 - accuracy: 0.3482\n",
      "Epoch 18/60\n",
      "600/600 - 1s - loss: 1.7864 - accuracy: 0.3489\n",
      "Epoch 19/60\n",
      "600/600 - 1s - loss: 1.7858 - accuracy: 0.3496\n",
      "Epoch 20/60\n",
      "600/600 - 1s - loss: 1.7848 - accuracy: 0.3501\n",
      "Epoch 21/60\n",
      "600/600 - 1s - loss: 1.7842 - accuracy: 0.3503\n",
      "Epoch 22/60\n",
      "600/600 - 1s - loss: 1.7835 - accuracy: 0.3504\n",
      "Epoch 23/60\n",
      "600/600 - 1s - loss: 1.7828 - accuracy: 0.3501\n",
      "Epoch 24/60\n",
      "600/600 - 1s - loss: 1.7822 - accuracy: 0.3504\n",
      "Epoch 25/60\n",
      "600/600 - 1s - loss: 1.7817 - accuracy: 0.3506\n",
      "Epoch 26/60\n",
      "600/600 - 1s - loss: 1.7815 - accuracy: 0.3507\n",
      "Epoch 27/60\n",
      "600/600 - 1s - loss: 1.7812 - accuracy: 0.3507\n",
      "Epoch 28/60\n",
      "600/600 - 1s - loss: 1.7809 - accuracy: 0.3509\n",
      "Epoch 29/60\n",
      "600/600 - 1s - loss: 1.7807 - accuracy: 0.3510\n",
      "Epoch 30/60\n",
      "600/600 - 1s - loss: 1.7804 - accuracy: 0.3512\n",
      "Epoch 31/60\n",
      "600/600 - 1s - loss: 1.7801 - accuracy: 0.3518\n",
      "Epoch 32/60\n",
      "600/600 - 1s - loss: 1.7803 - accuracy: 0.3513\n",
      "Epoch 33/60\n",
      "600/600 - 1s - loss: 1.7797 - accuracy: 0.3516\n",
      "Epoch 34/60\n",
      "600/600 - 1s - loss: 1.7796 - accuracy: 0.3509\n",
      "Epoch 35/60\n",
      "600/600 - 1s - loss: 1.7794 - accuracy: 0.3518\n",
      "Epoch 36/60\n",
      "600/600 - 1s - loss: 1.7793 - accuracy: 0.3513\n",
      "Epoch 37/60\n",
      "600/600 - 1s - loss: 1.7791 - accuracy: 0.3517\n",
      "Epoch 38/60\n",
      "600/600 - 1s - loss: 1.7790 - accuracy: 0.3520\n",
      "Epoch 39/60\n",
      "600/600 - 1s - loss: 1.7788 - accuracy: 0.3514\n",
      "Epoch 40/60\n",
      "600/600 - 1s - loss: 1.7786 - accuracy: 0.3516\n",
      "Epoch 41/60\n",
      "600/600 - 1s - loss: 1.7785 - accuracy: 0.3515\n",
      "Epoch 42/60\n",
      "600/600 - 1s - loss: 1.7784 - accuracy: 0.3517\n",
      "Epoch 43/60\n",
      "600/600 - 1s - loss: 1.7784 - accuracy: 0.3515\n",
      "Epoch 44/60\n",
      "600/600 - 1s - loss: 1.7783 - accuracy: 0.3515\n",
      "Epoch 45/60\n",
      "600/600 - 1s - loss: 1.7783 - accuracy: 0.3514\n",
      "Epoch 46/60\n",
      "600/600 - 1s - loss: 1.7782 - accuracy: 0.3518\n",
      "Epoch 47/60\n",
      "600/600 - 1s - loss: 1.7781 - accuracy: 0.3515\n",
      "Epoch 48/60\n",
      "600/600 - 1s - loss: 1.7781 - accuracy: 0.3516\n",
      "Epoch 49/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3514\n",
      "Epoch 50/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3523\n",
      "Epoch 51/60\n",
      "600/600 - 1s - loss: 1.7780 - accuracy: 0.3520\n",
      "Epoch 52/60\n",
      "600/600 - 1s - loss: 1.7778 - accuracy: 0.3524\n",
      "Epoch 53/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3522\n",
      "Epoch 54/60\n",
      "600/600 - 1s - loss: 1.7777 - accuracy: 0.3521\n",
      "Epoch 55/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3521\n",
      "Epoch 56/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3517\n",
      "Epoch 57/60\n",
      "600/600 - 1s - loss: 1.7775 - accuracy: 0.3522\n",
      "Epoch 58/60\n",
      "600/600 - 1s - loss: 1.7774 - accuracy: 0.3515\n",
      "Epoch 59/60\n",
      "600/600 - 1s - loss: 1.7772 - accuracy: 0.3518\n",
      "Epoch 60/60\n",
      "600/600 - 1s - loss: 1.7772 - accuracy: 0.3521\n",
      "25/25 - 0s - loss: 1.7866 - accuracy: 0.3533\n",
      "Epoch 1/60\n",
      "600/600 - 1s - loss: 2.4118 - accuracy: 0.2575\n",
      "Epoch 2/60\n",
      "600/600 - 1s - loss: 1.8709 - accuracy: 0.3102\n",
      "Epoch 3/60\n",
      "600/600 - 1s - loss: 1.8398 - accuracy: 0.3394\n",
      "Epoch 4/60\n",
      "600/600 - 1s - loss: 1.8263 - accuracy: 0.3447\n",
      "Epoch 5/60\n",
      "600/600 - 1s - loss: 1.8189 - accuracy: 0.3434\n",
      "Epoch 6/60\n",
      "600/600 - 1s - loss: 1.8139 - accuracy: 0.3433\n",
      "Epoch 7/60\n",
      "600/600 - 1s - loss: 1.8056 - accuracy: 0.3448\n",
      "Epoch 8/60\n",
      "600/600 - 1s - loss: 1.7984 - accuracy: 0.3446\n",
      "Epoch 9/60\n",
      "600/600 - 1s - loss: 1.7947 - accuracy: 0.3439\n",
      "Epoch 10/60\n",
      "600/600 - 1s - loss: 1.7925 - accuracy: 0.3447\n",
      "Epoch 11/60\n",
      "600/600 - 1s - loss: 1.7910 - accuracy: 0.3454\n",
      "Epoch 12/60\n",
      "600/600 - 1s - loss: 1.7900 - accuracy: 0.3457\n",
      "Epoch 13/60\n",
      "600/600 - 1s - loss: 1.7891 - accuracy: 0.3473\n",
      "Epoch 14/60\n",
      "600/600 - 1s - loss: 1.7882 - accuracy: 0.3466\n",
      "Epoch 15/60\n",
      "600/600 - 1s - loss: 1.7873 - accuracy: 0.3476\n",
      "Epoch 16/60\n",
      "600/600 - 1s - loss: 1.7867 - accuracy: 0.3473\n",
      "Epoch 17/60\n",
      "600/600 - 1s - loss: 1.7857 - accuracy: 0.3477\n",
      "Epoch 18/60\n",
      "600/600 - 1s - loss: 1.7849 - accuracy: 0.3491\n",
      "Epoch 19/60\n",
      "600/600 - 1s - loss: 1.7840 - accuracy: 0.3489\n",
      "Epoch 20/60\n",
      "600/600 - 1s - loss: 1.7830 - accuracy: 0.3499\n",
      "Epoch 21/60\n",
      "600/600 - 1s - loss: 1.7823 - accuracy: 0.3498\n",
      "Epoch 22/60\n",
      "600/600 - 1s - loss: 1.7816 - accuracy: 0.3509\n",
      "Epoch 23/60\n",
      "600/600 - 1s - loss: 1.7810 - accuracy: 0.3508\n",
      "Epoch 24/60\n",
      "600/600 - 1s - loss: 1.7805 - accuracy: 0.3510\n",
      "Epoch 25/60\n",
      "600/600 - 1s - loss: 1.7798 - accuracy: 0.3517\n",
      "Epoch 26/60\n",
      "600/600 - 1s - loss: 1.7795 - accuracy: 0.3520\n",
      "Epoch 27/60\n",
      "600/600 - 1s - loss: 1.7790 - accuracy: 0.3513\n",
      "Epoch 28/60\n",
      "600/600 - 1s - loss: 1.7786 - accuracy: 0.3515\n",
      "Epoch 29/60\n",
      "600/600 - 1s - loss: 1.7782 - accuracy: 0.3521\n",
      "Epoch 30/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3520\n",
      "Epoch 31/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3525\n",
      "Epoch 32/60\n",
      "600/600 - 1s - loss: 1.7773 - accuracy: 0.3524\n",
      "Epoch 33/60\n",
      "600/600 - 1s - loss: 1.7772 - accuracy: 0.3528\n",
      "Epoch 34/60\n",
      "600/600 - 1s - loss: 1.7769 - accuracy: 0.3527\n",
      "Epoch 35/60\n",
      "600/600 - 1s - loss: 1.7766 - accuracy: 0.3529\n",
      "Epoch 36/60\n",
      "600/600 - 1s - loss: 1.7766 - accuracy: 0.3528\n",
      "Epoch 37/60\n",
      "600/600 - 1s - loss: 1.7762 - accuracy: 0.3531\n",
      "Epoch 38/60\n",
      "600/600 - 1s - loss: 1.7762 - accuracy: 0.3525\n",
      "Epoch 39/60\n",
      "600/600 - 1s - loss: 1.7760 - accuracy: 0.3519\n",
      "Epoch 40/60\n",
      "600/600 - 1s - loss: 1.7756 - accuracy: 0.3529\n",
      "Epoch 41/60\n",
      "600/600 - 1s - loss: 1.7756 - accuracy: 0.3526\n",
      "Epoch 42/60\n",
      "600/600 - 1s - loss: 1.7755 - accuracy: 0.3529\n",
      "Epoch 43/60\n",
      "600/600 - 1s - loss: 1.7754 - accuracy: 0.3523\n",
      "Epoch 44/60\n",
      "600/600 - 1s - loss: 1.7752 - accuracy: 0.3529\n",
      "Epoch 45/60\n",
      "600/600 - 1s - loss: 1.7751 - accuracy: 0.3527\n",
      "Epoch 46/60\n",
      "600/600 - 1s - loss: 1.7750 - accuracy: 0.3533\n",
      "Epoch 47/60\n",
      "600/600 - 1s - loss: 1.7749 - accuracy: 0.3524\n",
      "Epoch 48/60\n",
      "600/600 - 1s - loss: 1.7747 - accuracy: 0.3527\n",
      "Epoch 49/60\n",
      "600/600 - 1s - loss: 1.7748 - accuracy: 0.3530\n",
      "Epoch 50/60\n",
      "600/600 - 1s - loss: 1.7748 - accuracy: 0.3529\n",
      "Epoch 51/60\n",
      "600/600 - 1s - loss: 1.7747 - accuracy: 0.3526\n",
      "Epoch 52/60\n",
      "600/600 - 1s - loss: 1.7746 - accuracy: 0.3521\n",
      "Epoch 53/60\n",
      "600/600 - 1s - loss: 1.7745 - accuracy: 0.3526\n",
      "Epoch 54/60\n",
      "600/600 - 1s - loss: 1.7745 - accuracy: 0.3521\n",
      "Epoch 55/60\n",
      "600/600 - 1s - loss: 1.7743 - accuracy: 0.3527\n",
      "Epoch 56/60\n",
      "600/600 - 1s - loss: 1.7743 - accuracy: 0.3529\n",
      "Epoch 57/60\n",
      "600/600 - 1s - loss: 1.7743 - accuracy: 0.3522\n",
      "Epoch 58/60\n",
      "600/600 - 1s - loss: 1.7743 - accuracy: 0.3523\n",
      "Epoch 59/60\n",
      "600/600 - 1s - loss: 1.7742 - accuracy: 0.3526\n",
      "Epoch 60/60\n",
      "600/600 - 1s - loss: 1.7743 - accuracy: 0.3528\n",
      "25/25 - 0s - loss: 1.7735 - accuracy: 0.3484\n",
      "Epoch 1/60\n",
      "600/600 - 1s - loss: 2.4383 - accuracy: 0.2241\n",
      "Epoch 2/60\n",
      "600/600 - 1s - loss: 1.9445 - accuracy: 0.2657\n",
      "Epoch 3/60\n",
      "600/600 - 1s - loss: 1.8875 - accuracy: 0.2924\n",
      "Epoch 4/60\n",
      "600/600 - 1s - loss: 1.8516 - accuracy: 0.3116\n",
      "Epoch 5/60\n",
      "600/600 - 1s - loss: 1.8291 - accuracy: 0.3305\n",
      "Epoch 6/60\n",
      "600/600 - 1s - loss: 1.8200 - accuracy: 0.3435\n",
      "Epoch 7/60\n",
      "600/600 - 1s - loss: 1.8147 - accuracy: 0.3435\n",
      "Epoch 8/60\n",
      "600/600 - 1s - loss: 1.8085 - accuracy: 0.3439\n",
      "Epoch 9/60\n",
      "600/600 - 1s - loss: 1.8027 - accuracy: 0.3441\n",
      "Epoch 10/60\n",
      "600/600 - 1s - loss: 1.7985 - accuracy: 0.3446\n",
      "Epoch 11/60\n",
      "600/600 - 1s - loss: 1.7961 - accuracy: 0.3454\n",
      "Epoch 12/60\n",
      "600/600 - 1s - loss: 1.7944 - accuracy: 0.3460\n",
      "Epoch 13/60\n",
      "600/600 - 1s - loss: 1.7935 - accuracy: 0.3466\n",
      "Epoch 14/60\n",
      "600/600 - 1s - loss: 1.7928 - accuracy: 0.3472\n",
      "Epoch 15/60\n",
      "600/600 - 1s - loss: 1.7920 - accuracy: 0.3475\n",
      "Epoch 16/60\n",
      "600/600 - 1s - loss: 1.7916 - accuracy: 0.3477\n",
      "Epoch 17/60\n",
      "600/600 - 1s - loss: 1.7910 - accuracy: 0.3484\n",
      "Epoch 18/60\n",
      "600/600 - 1s - loss: 1.7907 - accuracy: 0.3477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "600/600 - 1s - loss: 1.7902 - accuracy: 0.3486\n",
      "Epoch 20/60\n",
      "600/600 - 1s - loss: 1.7898 - accuracy: 0.3483\n",
      "Epoch 21/60\n",
      "600/600 - 1s - loss: 1.7893 - accuracy: 0.3486\n",
      "Epoch 22/60\n",
      "600/600 - 1s - loss: 1.7886 - accuracy: 0.3487\n",
      "Epoch 23/60\n",
      "600/600 - 1s - loss: 1.7880 - accuracy: 0.3491\n",
      "Epoch 24/60\n",
      "600/600 - 1s - loss: 1.7876 - accuracy: 0.3488\n",
      "Epoch 25/60\n",
      "600/600 - 1s - loss: 1.7871 - accuracy: 0.3490\n",
      "Epoch 26/60\n",
      "600/600 - 1s - loss: 1.7866 - accuracy: 0.3494\n",
      "Epoch 27/60\n",
      "600/600 - 1s - loss: 1.7861 - accuracy: 0.3492\n",
      "Epoch 28/60\n",
      "600/600 - 1s - loss: 1.7859 - accuracy: 0.3498\n",
      "Epoch 29/60\n",
      "600/600 - 1s - loss: 1.7857 - accuracy: 0.3494\n",
      "Epoch 30/60\n",
      "600/600 - 1s - loss: 1.7852 - accuracy: 0.3496\n",
      "Epoch 31/60\n",
      "600/600 - 1s - loss: 1.7849 - accuracy: 0.3498\n",
      "Epoch 32/60\n",
      "600/600 - 1s - loss: 1.7847 - accuracy: 0.3495\n",
      "Epoch 33/60\n",
      "600/600 - 1s - loss: 1.7846 - accuracy: 0.3497\n",
      "Epoch 34/60\n",
      "600/600 - 1s - loss: 1.7843 - accuracy: 0.3495\n",
      "Epoch 35/60\n",
      "600/600 - 1s - loss: 1.7842 - accuracy: 0.3500\n",
      "Epoch 36/60\n",
      "600/600 - 1s - loss: 1.7836 - accuracy: 0.3502\n",
      "Epoch 37/60\n",
      "600/600 - 1s - loss: 1.7836 - accuracy: 0.3501\n",
      "Epoch 38/60\n",
      "600/600 - 1s - loss: 1.7834 - accuracy: 0.3505\n",
      "Epoch 39/60\n",
      "600/600 - 1s - loss: 1.7831 - accuracy: 0.3506\n",
      "Epoch 40/60\n",
      "600/600 - 1s - loss: 1.7829 - accuracy: 0.3500\n",
      "Epoch 41/60\n",
      "600/600 - 1s - loss: 1.7826 - accuracy: 0.3506\n",
      "Epoch 42/60\n",
      "600/600 - 1s - loss: 1.7821 - accuracy: 0.3510\n",
      "Epoch 43/60\n",
      "600/600 - 1s - loss: 1.7817 - accuracy: 0.3505\n",
      "Epoch 44/60\n",
      "600/600 - 1s - loss: 1.7812 - accuracy: 0.3512\n",
      "Epoch 45/60\n",
      "600/600 - 1s - loss: 1.7810 - accuracy: 0.3505\n",
      "Epoch 46/60\n",
      "600/600 - 1s - loss: 1.7805 - accuracy: 0.3507\n",
      "Epoch 47/60\n",
      "600/600 - 1s - loss: 1.7803 - accuracy: 0.3499\n",
      "Epoch 48/60\n",
      "600/600 - 1s - loss: 1.7798 - accuracy: 0.3502\n",
      "Epoch 49/60\n",
      "600/600 - 1s - loss: 1.7793 - accuracy: 0.3509\n",
      "Epoch 50/60\n",
      "600/600 - 1s - loss: 1.7790 - accuracy: 0.3507\n",
      "Epoch 51/60\n",
      "600/600 - 1s - loss: 1.7787 - accuracy: 0.3504\n",
      "Epoch 52/60\n",
      "600/600 - 1s - loss: 1.7783 - accuracy: 0.3510\n",
      "Epoch 53/60\n",
      "600/600 - 1s - loss: 1.7780 - accuracy: 0.3510\n",
      "Epoch 54/60\n",
      "600/600 - 1s - loss: 1.7777 - accuracy: 0.3516\n",
      "Epoch 55/60\n",
      "600/600 - 1s - loss: 1.7774 - accuracy: 0.3517\n",
      "Epoch 56/60\n",
      "600/600 - 1s - loss: 1.7771 - accuracy: 0.3516\n",
      "Epoch 57/60\n",
      "600/600 - 1s - loss: 1.7768 - accuracy: 0.3516\n",
      "Epoch 58/60\n",
      "600/600 - 1s - loss: 1.7766 - accuracy: 0.3524\n",
      "Epoch 59/60\n",
      "600/600 - 1s - loss: 1.7764 - accuracy: 0.3517\n",
      "Epoch 60/60\n",
      "600/600 - 1s - loss: 1.7760 - accuracy: 0.3521\n",
      "25/25 - 0s - loss: 1.7888 - accuracy: 0.3519\n",
      "Epoch 1/60\n",
      "600/600 - 1s - loss: 2.2336 - accuracy: 0.2481\n",
      "Epoch 2/60\n",
      "600/600 - 1s - loss: 1.8777 - accuracy: 0.2791\n",
      "Epoch 3/60\n",
      "600/600 - 1s - loss: 1.8511 - accuracy: 0.2996\n",
      "Epoch 4/60\n",
      "600/600 - 1s - loss: 1.8401 - accuracy: 0.3016\n",
      "Epoch 5/60\n",
      "600/600 - 1s - loss: 1.8338 - accuracy: 0.3030\n",
      "Epoch 6/60\n",
      "600/600 - 1s - loss: 1.8297 - accuracy: 0.3049\n",
      "Epoch 7/60\n",
      "600/600 - 1s - loss: 1.8270 - accuracy: 0.3080\n",
      "Epoch 8/60\n",
      "600/600 - 1s - loss: 1.8254 - accuracy: 0.3094\n",
      "Epoch 9/60\n",
      "600/600 - 1s - loss: 1.8238 - accuracy: 0.3175\n",
      "Epoch 10/60\n",
      "600/600 - 1s - loss: 1.8209 - accuracy: 0.3266\n",
      "Epoch 11/60\n",
      "600/600 - 1s - loss: 1.8162 - accuracy: 0.3341\n",
      "Epoch 12/60\n",
      "600/600 - 1s - loss: 1.8071 - accuracy: 0.3387\n",
      "Epoch 13/60\n",
      "600/600 - 1s - loss: 1.7982 - accuracy: 0.3422\n",
      "Epoch 14/60\n",
      "600/600 - 1s - loss: 1.7946 - accuracy: 0.3444\n",
      "Epoch 15/60\n",
      "600/600 - 1s - loss: 1.7918 - accuracy: 0.3457\n",
      "Epoch 16/60\n",
      "600/600 - 1s - loss: 1.7895 - accuracy: 0.3467\n",
      "Epoch 17/60\n",
      "600/600 - 1s - loss: 1.7877 - accuracy: 0.3467\n",
      "Epoch 18/60\n",
      "600/600 - 1s - loss: 1.7860 - accuracy: 0.3481\n",
      "Epoch 19/60\n",
      "600/600 - 1s - loss: 1.7846 - accuracy: 0.3487\n",
      "Epoch 20/60\n",
      "600/600 - 1s - loss: 1.7838 - accuracy: 0.3484\n",
      "Epoch 21/60\n",
      "600/600 - 1s - loss: 1.7829 - accuracy: 0.3486\n",
      "Epoch 22/60\n",
      "600/600 - 1s - loss: 1.7827 - accuracy: 0.3486\n",
      "Epoch 23/60\n",
      "600/600 - 1s - loss: 1.7823 - accuracy: 0.3485\n",
      "Epoch 24/60\n",
      "600/600 - 1s - loss: 1.7820 - accuracy: 0.3481\n",
      "Epoch 25/60\n",
      "600/600 - 1s - loss: 1.7818 - accuracy: 0.3490\n",
      "Epoch 26/60\n",
      "600/600 - 1s - loss: 1.7817 - accuracy: 0.3484\n",
      "Epoch 27/60\n",
      "600/600 - 1s - loss: 1.7813 - accuracy: 0.3487\n",
      "Epoch 28/60\n",
      "600/600 - 1s - loss: 1.7810 - accuracy: 0.3486\n",
      "Epoch 29/60\n",
      "600/600 - 1s - loss: 1.7807 - accuracy: 0.3494\n",
      "Epoch 30/60\n",
      "600/600 - 1s - loss: 1.7804 - accuracy: 0.3487\n",
      "Epoch 31/60\n",
      "600/600 - 1s - loss: 1.7803 - accuracy: 0.3486\n",
      "Epoch 32/60\n",
      "600/600 - 1s - loss: 1.7800 - accuracy: 0.3487\n",
      "Epoch 33/60\n",
      "600/600 - 1s - loss: 1.7797 - accuracy: 0.3486\n",
      "Epoch 34/60\n",
      "600/600 - 1s - loss: 1.7795 - accuracy: 0.3488\n",
      "Epoch 35/60\n",
      "600/600 - 1s - loss: 1.7795 - accuracy: 0.3487\n",
      "Epoch 36/60\n",
      "600/600 - 1s - loss: 1.7793 - accuracy: 0.3487\n",
      "Epoch 37/60\n",
      "600/600 - 1s - loss: 1.7788 - accuracy: 0.3487\n",
      "Epoch 38/60\n",
      "600/600 - 1s - loss: 1.7785 - accuracy: 0.3487\n",
      "Epoch 39/60\n",
      "600/600 - 1s - loss: 1.7781 - accuracy: 0.3485\n",
      "Epoch 40/60\n",
      "600/600 - 1s - loss: 1.7780 - accuracy: 0.3473\n",
      "Epoch 41/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3470\n",
      "Epoch 42/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3502\n",
      "Epoch 43/60\n",
      "600/600 - 1s - loss: 1.7777 - accuracy: 0.3502\n",
      "Epoch 44/60\n",
      "600/600 - 1s - loss: 1.7774 - accuracy: 0.3505\n",
      "Epoch 45/60\n",
      "600/600 - 1s - loss: 1.7774 - accuracy: 0.3500\n",
      "Epoch 46/60\n",
      "600/600 - 1s - loss: 1.7771 - accuracy: 0.3502\n",
      "Epoch 47/60\n",
      "600/600 - 1s - loss: 1.7769 - accuracy: 0.3496\n",
      "Epoch 48/60\n",
      "600/600 - 1s - loss: 1.7769 - accuracy: 0.3502\n",
      "Epoch 49/60\n",
      "600/600 - 1s - loss: 1.7769 - accuracy: 0.3512\n",
      "Epoch 50/60\n",
      "600/600 - 1s - loss: 1.7768 - accuracy: 0.3510\n",
      "Epoch 51/60\n",
      "600/600 - 1s - loss: 1.7768 - accuracy: 0.3507\n",
      "Epoch 52/60\n",
      "600/600 - 1s - loss: 1.7765 - accuracy: 0.3511\n",
      "Epoch 53/60\n",
      "600/600 - 1s - loss: 1.7763 - accuracy: 0.3515\n",
      "Epoch 54/60\n",
      "600/600 - 1s - loss: 1.7764 - accuracy: 0.3518\n",
      "Epoch 55/60\n",
      "600/600 - 1s - loss: 1.7762 - accuracy: 0.3513\n",
      "Epoch 56/60\n",
      "600/600 - 1s - loss: 1.7763 - accuracy: 0.3515\n",
      "Epoch 57/60\n",
      "600/600 - 1s - loss: 1.7761 - accuracy: 0.3513\n",
      "Epoch 58/60\n",
      "600/600 - 1s - loss: 1.7761 - accuracy: 0.3516\n",
      "Epoch 59/60\n",
      "600/600 - 1s - loss: 1.7760 - accuracy: 0.3511\n",
      "Epoch 60/60\n",
      "600/600 - 1s - loss: 1.7760 - accuracy: 0.3511\n",
      "25/25 - 0s - loss: 1.7848 - accuracy: 0.3520\n",
      "Epoch 1/60\n",
      "600/600 - 1s - loss: 2.2616 - accuracy: 0.2422\n",
      "Epoch 2/60\n",
      "600/600 - 1s - loss: 1.9327 - accuracy: 0.2897\n",
      "Epoch 3/60\n",
      "600/600 - 1s - loss: 1.8826 - accuracy: 0.3038\n",
      "Epoch 4/60\n",
      "600/600 - 1s - loss: 1.8539 - accuracy: 0.3180\n",
      "Epoch 5/60\n",
      "600/600 - 1s - loss: 1.8213 - accuracy: 0.3378\n",
      "Epoch 6/60\n",
      "600/600 - 1s - loss: 1.8038 - accuracy: 0.3437\n",
      "Epoch 7/60\n",
      "600/600 - 1s - loss: 1.7956 - accuracy: 0.3459\n",
      "Epoch 8/60\n",
      "600/600 - 1s - loss: 1.7925 - accuracy: 0.3463\n",
      "Epoch 9/60\n",
      "600/600 - 1s - loss: 1.7907 - accuracy: 0.3472\n",
      "Epoch 10/60\n",
      "600/600 - 1s - loss: 1.7898 - accuracy: 0.3479\n",
      "Epoch 11/60\n",
      "600/600 - 1s - loss: 1.7890 - accuracy: 0.3480\n",
      "Epoch 12/60\n",
      "600/600 - 1s - loss: 1.7884 - accuracy: 0.3477\n",
      "Epoch 13/60\n",
      "600/600 - 1s - loss: 1.7876 - accuracy: 0.3480\n",
      "Epoch 14/60\n",
      "600/600 - 1s - loss: 1.7870 - accuracy: 0.3485\n",
      "Epoch 15/60\n",
      "600/600 - 1s - loss: 1.7863 - accuracy: 0.3485\n",
      "Epoch 16/60\n",
      "600/600 - 1s - loss: 1.7858 - accuracy: 0.3486\n",
      "Epoch 17/60\n",
      "600/600 - 1s - loss: 1.7853 - accuracy: 0.3490\n",
      "Epoch 18/60\n",
      "600/600 - 1s - loss: 1.7849 - accuracy: 0.3494\n",
      "Epoch 19/60\n",
      "600/600 - 1s - loss: 1.7845 - accuracy: 0.3496\n",
      "Epoch 20/60\n",
      "600/600 - 1s - loss: 1.7841 - accuracy: 0.3497\n",
      "Epoch 21/60\n",
      "600/600 - 1s - loss: 1.7839 - accuracy: 0.3495\n",
      "Epoch 22/60\n",
      "600/600 - 1s - loss: 1.7835 - accuracy: 0.3496\n",
      "Epoch 23/60\n",
      "600/600 - 1s - loss: 1.7836 - accuracy: 0.3500\n",
      "Epoch 24/60\n",
      "600/600 - 1s - loss: 1.7832 - accuracy: 0.3502\n",
      "Epoch 25/60\n",
      "600/600 - 1s - loss: 1.7830 - accuracy: 0.3500\n",
      "Epoch 26/60\n",
      "600/600 - 1s - loss: 1.7827 - accuracy: 0.3499\n",
      "Epoch 27/60\n",
      "600/600 - 1s - loss: 1.7824 - accuracy: 0.3502\n",
      "Epoch 28/60\n",
      "600/600 - 1s - loss: 1.7820 - accuracy: 0.3501\n",
      "Epoch 29/60\n",
      "600/600 - 1s - loss: 1.7814 - accuracy: 0.3504\n",
      "Epoch 30/60\n",
      "600/600 - 1s - loss: 1.7811 - accuracy: 0.3501\n",
      "Epoch 31/60\n",
      "600/600 - 1s - loss: 1.7807 - accuracy: 0.3504\n",
      "Epoch 32/60\n",
      "600/600 - 1s - loss: 1.7801 - accuracy: 0.3501\n",
      "Epoch 33/60\n",
      "600/600 - 1s - loss: 1.7798 - accuracy: 0.3502\n",
      "Epoch 34/60\n",
      "600/600 - 1s - loss: 1.7794 - accuracy: 0.3509\n",
      "Epoch 35/60\n",
      "600/600 - 1s - loss: 1.7786 - accuracy: 0.3504\n",
      "Epoch 36/60\n",
      "600/600 - 1s - loss: 1.7783 - accuracy: 0.3508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "600/600 - 1s - loss: 1.7782 - accuracy: 0.3512\n",
      "Epoch 38/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3506\n",
      "Epoch 39/60\n",
      "600/600 - 1s - loss: 1.7777 - accuracy: 0.3518\n",
      "Epoch 40/60\n",
      "600/600 - 1s - loss: 1.7779 - accuracy: 0.3513\n",
      "Epoch 41/60\n",
      "600/600 - 1s - loss: 1.7776 - accuracy: 0.3506\n",
      "Epoch 42/60\n",
      "600/600 - 1s - loss: 1.7775 - accuracy: 0.3512\n",
      "Epoch 43/60\n",
      "600/600 - 1s - loss: 1.7773 - accuracy: 0.3512\n",
      "Epoch 44/60\n",
      "600/600 - 1s - loss: 1.7772 - accuracy: 0.3509\n",
      "Epoch 45/60\n",
      "600/600 - 1s - loss: 1.7773 - accuracy: 0.3510\n",
      "Epoch 46/60\n",
      "600/600 - 1s - loss: 1.7772 - accuracy: 0.3511\n",
      "Epoch 47/60\n",
      "600/600 - 1s - loss: 1.7769 - accuracy: 0.3502\n",
      "Epoch 48/60\n",
      "600/600 - 1s - loss: 1.7768 - accuracy: 0.3505\n",
      "Epoch 49/60\n",
      "600/600 - 1s - loss: 1.7764 - accuracy: 0.3512\n",
      "Epoch 50/60\n",
      "600/600 - 1s - loss: 1.7765 - accuracy: 0.3510\n",
      "Epoch 51/60\n",
      "600/600 - 1s - loss: 1.7762 - accuracy: 0.3512\n",
      "Epoch 52/60\n",
      "600/600 - 1s - loss: 1.7761 - accuracy: 0.3509\n",
      "Epoch 53/60\n",
      "600/600 - 1s - loss: 1.7760 - accuracy: 0.3512\n",
      "Epoch 54/60\n",
      "600/600 - 1s - loss: 1.7758 - accuracy: 0.3516\n",
      "Epoch 55/60\n",
      "600/600 - 1s - loss: 1.7758 - accuracy: 0.3512\n",
      "Epoch 56/60\n"
     ]
    }
   ],
   "source": [
    "import datetime;\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "grid_search = GridSearchCV(estimator = estimator, cv = kfold, param_grid = {})\n",
    "grid_search = grid_search.fit(X_train, dummy_y)\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "198a7210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "157/157 [==============================] - 0s 939us/step\n",
      "1.8434893054716288\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_Y = encoder.transform(y_test)\n",
    "test_dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "test_dummy_y = test_dummy_y.astype(int)\n",
    "test_y_dim = np.shape(test_dummy_y)[1]\n",
    "\n",
    "X_test = X_test.values.astype(int)\n",
    "\n",
    "test_probs = grid_search.predict_proba(X_test)\n",
    "the_log_loss = abs(log_loss(test_dummy_y, test_probs))\n",
    "print(the_log_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
