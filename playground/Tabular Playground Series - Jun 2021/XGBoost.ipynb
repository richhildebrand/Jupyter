{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd40650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 166.7 MB 43 kB/s  eta 0:00:01    |████▊                           | 24.5 MB 329 kB/s eta 0:07:12     |█████████████████▏              | 89.7 MB 4.9 MB/s eta 0:00:16     |█████████████████████▉          | 113.8 MB 5.5 MB/s eta 0:00:10     |██████████████████████          | 114.6 MB 5.5 MB/s eta 0:00:10     |████████████████████████████    | 145.6 MB 5.7 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.6.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306a0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap-hypetune\n",
      "  Downloading shap_hypetune-0.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from shap-hypetune) (1.20.3)\n",
      "Collecting shap>=0.39.0\n",
      "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
      "\u001b[K     |████████████████████████████████| 356 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from shap-hypetune) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from shap>=0.39.0->shap-hypetune) (0.24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from shap>=0.39.0->shap-hypetune) (1.2.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/lib/python3.9/site-packages (from shap>=0.39.0->shap-hypetune) (4.61.1)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.9/site-packages (from shap>=0.39.0->shap-hypetune) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.9/site-packages (from shap>=0.39.0->shap-hypetune) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba->shap>=0.39.0->shap-hypetune) (49.6.0.post20210108)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba->shap>=0.39.0->shap-hypetune) (0.36.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->shap>=0.39.0->shap-hypetune) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->shap>=0.39.0->shap-hypetune) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->shap>=0.39.0->shap-hypetune) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->shap>=0.39.0->shap-hypetune) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->shap>=0.39.0->shap-hypetune) (2.1.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.39.0-cp39-cp39-linux_x86_64.whl size=418998 sha256=2718b633a05eef56d2cf265732acc81f2d675c4724cfe93b7ad3be4a3ad79d7f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/bb/91/16/f6a057925f93af7e4281f6afce3495b595b473342766eb451c\n",
      "Successfully built shap\n",
      "Installing collected packages: slicer, shap, shap-hypetune\n",
      "Successfully installed shap-0.39.0 shap-hypetune-0.1.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shap-hypetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471fd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008cd520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0          0          0          6          1          0          0   \n",
       "1   1          0          0          0          0          0          0   \n",
       "2   2          0          0          0          0          0          1   \n",
       "3   3          0          0          7          0          1          5   \n",
       "4   4          1          0          0          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_66  feature_67  feature_68  \\\n",
       "0          0          0          7  ...           0           0           0   \n",
       "1          0          0          0  ...           2           0           0   \n",
       "2          0          3          0  ...           0           0           0   \n",
       "3          2          2          0  ...           0           4           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_69  feature_70  feature_71  feature_72  feature_73  feature_74  \\\n",
       "0           0           0           0           2           0           0   \n",
       "1           0           0           0           0           1           0   \n",
       "2           0           1           0           0           0           0   \n",
       "3           2           2           0           4           3           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "    target  \n",
       "0  Class_6  \n",
       "1  Class_6  \n",
       "2  Class_2  \n",
       "3  Class_8  \n",
       "4  Class_2  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259009fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  200000          0          0          0          0          0          0   \n",
       "1  200001          1          2          0          0          0          0   \n",
       "2  200002          0          1          7          1          0          0   \n",
       "3  200003          0          0          0          4          3          1   \n",
       "4  200004          0          0          5          0          0          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_65  feature_66  feature_67  \\\n",
       "0          0          0          0  ...           0           0           0   \n",
       "1          0          0          0  ...           3           1           3   \n",
       "2          0          0          6  ...           3           0           0   \n",
       "3          0          0          0  ...           0           0           0   \n",
       "4          0          0          0  ...           0           0           0   \n",
       "\n",
       "   feature_68  feature_69  feature_70  feature_71  feature_72  feature_73  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           3           0   \n",
       "2           0           0           3           0           2           0   \n",
       "3           1           0           0           0           4           0   \n",
       "4           0           0           0           0           0           1   \n",
       "\n",
       "   feature_74  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3d2ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns = ['percent', 'depth', 'missing_features', 'log_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aed7cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"target\", data=train_df, order=train_df['target'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc6da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count:  20000\n",
      "test count:  180000\n"
     ]
    }
   ],
   "source": [
    "train_no_predict = train_df.drop(['id', 'target'], 1)\n",
    "train_predict = train_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_no_predict, train_predict, stratify=train_predict, train_size=0.10)\n",
    "print('train count: ', len(y_train))\n",
    "print('test count: ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3cd916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:51:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:53:19] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:55:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:57:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:59:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:01:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:06:04] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:08:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:10:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:12:17] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:16:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:18:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:20:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:22:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:24:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:26:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:28:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:30:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:32:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:36:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:38:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:43:00] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:45:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:47:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:49:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:51:32] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:55:41] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:57:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:59:48] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:01:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:04:11] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:06:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:08:34] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:10:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:12:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:14:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:16:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:19:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:21:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:28:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:30:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:43] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:34:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:36:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:38:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:42:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:44:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:46:12] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:06] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:49:49] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:51:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:53:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:55:10] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:56:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:58:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:00:13] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:01:53] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:03:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:04:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:06:25] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:07:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:05] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:10:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:08] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:11:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shaphypetune.BoostRFE>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shaphypetune import BoostRFE\n",
    "\n",
    "model = BoostRFE(XGBClassifier(), \n",
    "                 min_features_to_select=1, step=1,\n",
    "                 importance_type='shap_importances', train_importance=False)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f4fe940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(model.estimator_)\n",
    "print(model.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "860a6dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  1  1  1  1  1  9 14  1  1  1  2  1  1  1  5  1  1  1  1  1  1 12  1\n",
      "  4  1  1  6  1  1  1  1  1  1  1  3 11  1  1  1  1 13  8  1  1  1  1 15\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1 10]\n",
      "to_use [['feature_1']\n",
      " ['feature_2']\n",
      " ['feature_3']\n",
      " ['feature_4']\n",
      " ['feature_5']\n",
      " ['feature_8']\n",
      " ['feature_9']\n",
      " ['feature_10']\n",
      " ['feature_12']\n",
      " ['feature_13']\n",
      " ['feature_14']\n",
      " ['feature_16']\n",
      " ['feature_17']\n",
      " ['feature_18']\n",
      " ['feature_19']\n",
      " ['feature_20']\n",
      " ['feature_21']\n",
      " ['feature_23']\n",
      " ['feature_25']\n",
      " ['feature_26']\n",
      " ['feature_28']\n",
      " ['feature_29']\n",
      " ['feature_30']\n",
      " ['feature_31']\n",
      " ['feature_32']\n",
      " ['feature_33']\n",
      " ['feature_34']\n",
      " ['feature_37']\n",
      " ['feature_38']\n",
      " ['feature_39']\n",
      " ['feature_40']\n",
      " ['feature_43']\n",
      " ['feature_44']\n",
      " ['feature_45']\n",
      " ['feature_46']\n",
      " ['feature_48']\n",
      " ['feature_49']\n",
      " ['feature_50']\n",
      " ['feature_51']\n",
      " ['feature_52']\n",
      " ['feature_53']\n",
      " ['feature_54']\n",
      " ['feature_55']\n",
      " ['feature_56']\n",
      " ['feature_57']\n",
      " ['feature_58']\n",
      " ['feature_59']\n",
      " ['feature_60']\n",
      " ['feature_61']\n",
      " ['feature_62']\n",
      " ['feature_63']\n",
      " ['feature_64']\n",
      " ['feature_65']\n",
      " ['feature_66']\n",
      " ['feature_67']\n",
      " ['feature_68']\n",
      " ['feature_69']\n",
      " ['feature_70']\n",
      " ['feature_71']\n",
      " ['feature_72']\n",
      " ['feature_73']]\n",
      "to_avoid [['feature_0']\n",
      " ['feature_6']\n",
      " ['feature_7']\n",
      " ['feature_11']\n",
      " ['feature_15']\n",
      " ['feature_22']\n",
      " ['feature_24']\n",
      " ['feature_27']\n",
      " ['feature_35']\n",
      " ['feature_36']\n",
      " ['feature_41']\n",
      " ['feature_42']\n",
      " ['feature_47']\n",
      " ['feature_74']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n"
     ]
    }
   ],
   "source": [
    "dir(model)\n",
    "print(model.ranking_)\n",
    "dir(model.estimator_)\n",
    "#model.ranking_\n",
    "model.estimator_.evals_result_\n",
    "\n",
    "good_feature_indexes = np.argwhere(model.ranking_ <= 1)\n",
    "features_to_use = X_train.columns[good_feature_indexes]\n",
    "print('to_use', features_to_use)\n",
    "\n",
    "\n",
    "bad_feature_indexes = np.argwhere(model.ranking_ > 1)\n",
    "features_to_avoid = X_train.columns[bad_feature_indexes]\n",
    "print('to_avoid', features_to_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bad092eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_0 : 7\n",
      "feature_1 : 1\n",
      "feature_2 : 1\n",
      "feature_3 : 1\n",
      "feature_4 : 1\n",
      "feature_5 : 1\n",
      "feature_6 : 9\n",
      "feature_7 : 14\n",
      "feature_8 : 1\n",
      "feature_9 : 1\n",
      "feature_10 : 1\n",
      "feature_11 : 2\n",
      "feature_12 : 1\n",
      "feature_13 : 1\n",
      "feature_14 : 1\n",
      "feature_15 : 5\n",
      "feature_16 : 1\n",
      "feature_17 : 1\n",
      "feature_18 : 1\n",
      "feature_19 : 1\n",
      "feature_20 : 1\n",
      "feature_21 : 1\n",
      "feature_22 : 12\n",
      "feature_23 : 1\n",
      "feature_24 : 4\n",
      "feature_25 : 1\n",
      "feature_26 : 1\n",
      "feature_27 : 6\n",
      "feature_28 : 1\n",
      "feature_29 : 1\n",
      "feature_30 : 1\n",
      "feature_31 : 1\n",
      "feature_32 : 1\n",
      "feature_33 : 1\n",
      "feature_34 : 1\n",
      "feature_35 : 3\n",
      "feature_36 : 11\n",
      "feature_37 : 1\n",
      "feature_38 : 1\n",
      "feature_39 : 1\n",
      "feature_40 : 1\n",
      "feature_41 : 13\n",
      "feature_42 : 8\n",
      "feature_43 : 1\n",
      "feature_44 : 1\n",
      "feature_45 : 1\n",
      "feature_46 : 1\n",
      "feature_47 : 15\n",
      "feature_48 : 1\n",
      "feature_49 : 1\n",
      "feature_50 : 1\n",
      "feature_51 : 1\n",
      "feature_52 : 1\n",
      "feature_53 : 1\n",
      "feature_54 : 1\n",
      "feature_55 : 1\n",
      "feature_56 : 1\n",
      "feature_57 : 1\n",
      "feature_58 : 1\n",
      "feature_59 : 1\n",
      "feature_60 : 1\n",
      "feature_61 : 1\n",
      "feature_62 : 1\n",
      "feature_63 : 1\n",
      "feature_64 : 1\n",
      "feature_65 : 1\n",
      "feature_66 : 1\n",
      "feature_67 : 1\n",
      "feature_68 : 1\n",
      "feature_69 : 1\n",
      "feature_70 : 1\n",
      "feature_71 : 1\n",
      "feature_72 : 1\n",
      "feature_73 : 1\n",
      "feature_74 : 10\n"
     ]
    }
   ],
   "source": [
    "for i, rank in enumerate(model.ranking_):\n",
    "    feature = X_train.columns[i]\n",
    "    print(feature, ':', rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "af541e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:44:14.897245\n",
      "Fitting 6 folds for each of 1 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:06:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-06-19 00:07:12.995694\n"
     ]
    }
   ],
   "source": [
    "import datetime;\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "\n",
    "X_train_without_worst = X_train.drop(['feature_0', 'feature_6', 'feature_7', 'feature_11', 'feature_15', 'feature_22',\n",
    "                                      'feature_24', 'feature_27', 'feature_35', 'feature_36', 'feature_41', 'feature_42', \n",
    "                                      'feature_47', 'feature_74'], 1)\n",
    "X_test_without_worst = X_test.drop(['feature_0', 'feature_6', 'feature_7', 'feature_11', 'feature_15', 'feature_22',\n",
    "                                    'feature_24', 'feature_27', 'feature_35', 'feature_36', 'feature_41', 'feature_42', \n",
    "                                    'feature_47', 'feature_74'], 1)\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "parameters = { 'seed': [777], 'n_estimators': [250], \n",
    "               'learning_rate': [0.05], 'max_depth': [5], 'subsample': [0.5] }\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, \n",
    "                   cv=StratifiedKFold(n_splits=6, shuffle=True),\n",
    "                   n_jobs=-1, verbose=2, refit=True, scoring='neg_log_loss')\n",
    "\n",
    "clf.fit(X_train_without_worst, y_train)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f7f22d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 250, 'seed': 777, 'subsample': 0.5}\n",
      "test log_loss -1.77760593672416\n",
      "1.7721333809581896\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print('test log_loss', clf.best_score_)\n",
    "\n",
    "# run on the holdout data\n",
    "test_probs = clf.predict_proba(X_test_without_worst)\n",
    "the_log_loss = abs(log_loss(y_test, test_probs))\n",
    "print(the_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3e3332fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'percent':10, 'depth':5, \n",
    "           'missing_features': 'sub .5 - feature_0, feature_6, feature_7, feature_11, feature_15, feature_22 feature_24, feature_27, feature_35, feature_36, feature_41, feature_42, feature_47, feature_74', \n",
    "           'log_loss':the_log_loss }\n",
    "train_results = train_results.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e88c4dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent</th>\n",
       "      <th>depth</th>\n",
       "      <th>missing_features</th>\n",
       "      <th>log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>feature_7, feature_47</td>\n",
       "      <td>1.762934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>feature_47</td>\n",
       "      <td>1.762744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>feature_0, feature_6, feature_7, feature_11, f...</td>\n",
       "      <td>1.764524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>feature_0, feature_6, feature_7, feature_11, f...</td>\n",
       "      <td>1.778152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>sub .5 - feature_0, feature_6, feature_7, feat...</td>\n",
       "      <td>1.772133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  percent depth                                   missing_features  log_loss\n",
       "0      10     3                              feature_7, feature_47  1.762934\n",
       "1      10     3                                         feature_47  1.762744\n",
       "2      10     3  feature_0, feature_6, feature_7, feature_11, f...  1.764524\n",
       "3      10     6  feature_0, feature_6, feature_7, feature_11, f...  1.778152\n",
       "4      10     5  sub .5 - feature_0, feature_6, feature_7, feat...  1.772133"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "046b3f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
